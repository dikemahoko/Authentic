{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvyDfUiRx+TtGF3wXE7Dpo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dikemahoko/Authentic/blob/master/MUZAMANI_LEE_TADIWA_TSRWS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading the dataset zip file\n",
        "!wget https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Training_Images.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WmtnJeRai1TT",
        "outputId": "04a5617b-770c-4982-98b9-647698e3de07"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-17 21:19:03--  https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Training_Images.zip\n",
            "Resolving sid.erda.dk (sid.erda.dk)... 130.225.104.13\n",
            "Connecting to sid.erda.dk (sid.erda.dk)|130.225.104.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 276294756 (263M) [application/zip]\n",
            "Saving to: ‘GTSRB_Final_Training_Images.zip’\n",
            "\n",
            "GTSRB_Final_Trainin 100%[===================>] 263.50M  5.78MB/s    in 72s     \n",
            "\n",
            "2025-09-17 21:20:16 (3.64 MB/s) - ‘GTSRB_Final_Training_Images.zip’ saved [276294756/276294756]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!unzip -q GTSRB_Final_Training_Images.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6MOskXBMjrBV",
        "outputId": "76114bab-6107-433f-c178-fe9be61de233"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace GTSRB/Final_Training/Images/00000/00000_00000.ppm? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "la2XC5gqk1-T",
        "outputId": "90e699bb-a35d-4e64-e196-8b0ecb37f0fc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GTSRB  GTSRB_Final_Training_Images.zip\tsample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y tree\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BXuoY8v1lADq",
        "outputId": "b4bc102f-2d73-4d66-cdb9-9e44fc50e197"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tree\n",
            "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 47.9 kB of archives.\n",
            "After this operation, 116 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tree amd64 2.0.2-1 [47.9 kB]\n",
            "Fetched 47.9 kB in 0s (97.4 kB/s)\n",
            "Selecting previously unselected package tree.\n",
            "(Reading database ... 126435 files and directories currently installed.)\n",
            "Preparing to unpack .../tree_2.0.2-1_amd64.deb ...\n",
            "Unpacking tree (2.0.2-1) ...\n",
            "Setting up tree (2.0.2-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tree -L 3 GTSRB"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VjLq2kO9lFhD",
        "outputId": "16259e46-f381-4ab2-a366-9a4e7b0c66fb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01;34mGTSRB\u001b[0m\n",
            "├── \u001b[01;34mFinal_Training\u001b[0m\n",
            "│   └── \u001b[01;34mImages\u001b[0m\n",
            "│       ├── \u001b[01;34m00000\u001b[0m\n",
            "│       ├── \u001b[01;34m00001\u001b[0m\n",
            "│       ├── \u001b[01;34m00002\u001b[0m\n",
            "│       ├── \u001b[01;34m00003\u001b[0m\n",
            "│       ├── \u001b[01;34m00004\u001b[0m\n",
            "│       ├── \u001b[01;34m00005\u001b[0m\n",
            "│       ├── \u001b[01;34m00006\u001b[0m\n",
            "│       ├── \u001b[01;34m00007\u001b[0m\n",
            "│       ├── \u001b[01;34m00008\u001b[0m\n",
            "│       ├── \u001b[01;34m00009\u001b[0m\n",
            "│       ├── \u001b[01;34m00010\u001b[0m\n",
            "│       ├── \u001b[01;34m00011\u001b[0m\n",
            "│       ├── \u001b[01;34m00012\u001b[0m\n",
            "│       ├── \u001b[01;34m00013\u001b[0m\n",
            "│       ├── \u001b[01;34m00014\u001b[0m\n",
            "│       ├── \u001b[01;34m00015\u001b[0m\n",
            "│       ├── \u001b[01;34m00016\u001b[0m\n",
            "│       ├── \u001b[01;34m00017\u001b[0m\n",
            "│       ├── \u001b[01;34m00018\u001b[0m\n",
            "│       ├── \u001b[01;34m00019\u001b[0m\n",
            "│       ├── \u001b[01;34m00020\u001b[0m\n",
            "│       ├── \u001b[01;34m00021\u001b[0m\n",
            "│       ├── \u001b[01;34m00022\u001b[0m\n",
            "│       ├── \u001b[01;34m00023\u001b[0m\n",
            "│       ├── \u001b[01;34m00024\u001b[0m\n",
            "│       ├── \u001b[01;34m00025\u001b[0m\n",
            "│       ├── \u001b[01;34m00026\u001b[0m\n",
            "│       ├── \u001b[01;34m00027\u001b[0m\n",
            "│       ├── \u001b[01;34m00028\u001b[0m\n",
            "│       ├── \u001b[01;34m00029\u001b[0m\n",
            "│       ├── \u001b[01;34m00030\u001b[0m\n",
            "│       ├── \u001b[01;34m00031\u001b[0m\n",
            "│       ├── \u001b[01;34m00032\u001b[0m\n",
            "│       ├── \u001b[01;34m00033\u001b[0m\n",
            "│       ├── \u001b[01;34m00034\u001b[0m\n",
            "│       ├── \u001b[01;34m00035\u001b[0m\n",
            "│       ├── \u001b[01;34m00036\u001b[0m\n",
            "│       ├── \u001b[01;34m00037\u001b[0m\n",
            "│       ├── \u001b[01;34m00038\u001b[0m\n",
            "│       ├── \u001b[01;34m00039\u001b[0m\n",
            "│       ├── \u001b[01;34m00040\u001b[0m\n",
            "│       ├── \u001b[01;34m00041\u001b[0m\n",
            "│       └── \u001b[01;34m00042\u001b[0m\n",
            "└── \u001b[00mReadme-Images.txt\u001b[0m\n",
            "\n",
            "45 directories, 1 file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing and Data Loading\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "# The path\n",
        "data_dir = '/content/GTSRB'\n",
        "IMG_HEIGHT = 32\n",
        "IMG_WIDTH = 32\n",
        "NUM_CATEGORIES = 43\n",
        "\n",
        "# --- Load Data Function ---\n",
        "def load_data(data_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for category in range(NUM_CATEGORIES):\n",
        "        category_path = os.path.join(data_dir, 'Final_Training', 'Images', str(category).zfill(5))\n",
        "        for img_name in os.listdir(category_path):\n",
        "            if img_name.endswith('.ppm'):\n",
        "                img_path = os.path.join(category_path, img_name)\n",
        "                try:\n",
        "                    img = cv2.imread(img_path)\n",
        "                    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
        "                    images.append(img)\n",
        "                    labels.append(category)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error loading {img_path}: {e}\")\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# --- Execute Loading and Pre-processing ---\n",
        "images, labels = load_data(data_dir)\n",
        "images = images / 255.0  # Normalize\n",
        "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "y_train = to_categorical(y_train, NUM_CATEGORIES)\n",
        "y_val = to_categorical(y_val, NUM_CATEGORIES)\n",
        "\n",
        "print(f\"Dataset loaded. Training samples: {len(X_train)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gwffGqDZlO3t",
        "outputId": "9af1c2fa-d622-42af-bf8c-2e73a88c9a10"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded. Training samples: 31367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "data_generator = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.15,\n",
        "    fill_mode=\"nearest\"\n",
        ")"
      ],
      "metadata": {
        "id": "kDZpoSqdltNS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Building and Training the Model"
      ],
      "metadata": {
        "id": "Foy_dZ7_l8BK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "def build_model():\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.25),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.25),\n",
        "        Flatten(),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(NUM_CATEGORIES, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = build_model()\n",
        "history = model.fit(\n",
        "    data_generator.flow(X_train, y_train, batch_size=64),\n",
        "    epochs=25,\n",
        "    validation_data=(X_val, y_val)\n",
        ")\n",
        "\n",
        "# Saving the full Keras model first\n",
        "model.save('traffic_sign_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "NoDRvOk_l9G6",
        "outputId": "3b14cb37-f01c-47bb-e5ac-8f44a631ccc7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 141ms/step - accuracy: 0.2084 - loss: 2.9282 - val_accuracy: 0.6686 - val_loss: 1.1701\n",
            "Epoch 2/25\n",
            "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 132ms/step - accuracy: 0.5658 - loss: 1.3589 - val_accuracy: 0.8689 - val_loss: 0.5076\n",
            "Epoch 3/25\n",
            "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 126ms/step - accuracy: 0.7085 - loss: 0.8982 - val_accuracy: 0.9192 - val_loss: 0.3043\n",
            "Epoch 4/25\n",
            "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 133ms/step - accuracy: 0.7705 - loss: 0.6974 - val_accuracy: 0.9477 - val_loss: 0.2035\n",
            "Epoch 5/25\n",
            "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 128ms/step - accuracy: 0.8184 - loss: 0.5614 - val_accuracy: 0.9654 - val_loss: 0.1417\n",
            "Epoch 6/25\n",
            "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 130ms/step - accuracy: 0.8402 - loss: 0.4890 - val_accuracy: 0.9730 - val_loss: 0.1141\n",
            "Epoch 7/25\n",
            "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 131ms/step - accuracy: 0.8578 - loss: 0.4261 - val_accuracy: 0.9806 - val_loss: 0.0916\n",
            "Epoch 8/25\n",
            "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 126ms/step - accuracy: 0.8813 - loss: 0.3677 - val_accuracy: 0.9843 - val_loss: 0.0671\n",
            "Epoch 9/25\n",
            "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 133ms/step - accuracy: 0.8868 - loss: 0.3499 - val_accuracy: 0.9850 - val_loss: 0.0677\n",
            "Epoch 10/25\n",
            "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 134ms/step - accuracy: 0.8980 - loss: 0.3203 - val_accuracy: 0.9890 - val_loss: 0.0548\n",
            "Epoch 11/25\n",
            "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 133ms/step - accuracy: 0.9020 - loss: 0.3046 - val_accuracy: 0.9833 - val_loss: 0.0543\n",
            "Epoch 12/25\n",
            "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 132ms/step - accuracy: 0.9098 - loss: 0.2790 - val_accuracy: 0.9936 - val_loss: 0.0373\n",
            "Epoch 13/25\n",
            "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 133ms/step - accuracy: 0.9164 - loss: 0.2598 - val_accuracy: 0.9908 - val_loss: 0.0440\n",
            "Epoch 14/25\n",
            "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 133ms/step - accuracy: 0.9185 - loss: 0.2555 - val_accuracy: 0.9946 - val_loss: 0.0306\n",
            "Epoch 15/25\n",
            "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 131ms/step - accuracy: 0.9225 - loss: 0.2421 - val_accuracy: 0.9929 - val_loss: 0.0328\n",
            "Epoch 16/25\n",
            "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 133ms/step - accuracy: 0.9240 - loss: 0.2343 - val_accuracy: 0.9943 - val_loss: 0.0295\n",
            "Epoch 17/25\n",
            "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 135ms/step - accuracy: 0.9281 - loss: 0.2237 - val_accuracy: 0.9946 - val_loss: 0.0236\n",
            "Epoch 18/25\n",
            "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 136ms/step - accuracy: 0.9336 - loss: 0.2030 - val_accuracy: 0.9939 - val_loss: 0.0275\n",
            "Epoch 19/25\n",
            "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 134ms/step - accuracy: 0.9352 - loss: 0.1979 - val_accuracy: 0.9966 - val_loss: 0.0169\n",
            "Epoch 20/25\n",
            "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 131ms/step - accuracy: 0.9392 - loss: 0.1916 - val_accuracy: 0.9952 - val_loss: 0.0253\n",
            "Epoch 21/25\n",
            "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 126ms/step - accuracy: 0.9402 - loss: 0.1875 - val_accuracy: 0.9953 - val_loss: 0.0220\n",
            "Epoch 22/25\n",
            "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 129ms/step - accuracy: 0.9364 - loss: 0.1963 - val_accuracy: 0.9976 - val_loss: 0.0138\n",
            "Epoch 23/25\n",
            "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 129ms/step - accuracy: 0.9442 - loss: 0.1716 - val_accuracy: 0.9959 - val_loss: 0.0153\n",
            "Epoch 24/25\n",
            "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 137ms/step - accuracy: 0.9467 - loss: 0.1704 - val_accuracy: 0.9973 - val_loss: 0.0115\n",
            "Epoch 25/25\n",
            "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 131ms/step - accuracy: 0.9454 - loss: 0.1670 - val_accuracy: 0.9971 - val_loss: 0.0120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting to TFLite\n",
        "# Loading the saved Keras model\n",
        "keras_model = tf.keras.models.load_model('traffic_sign_model.h5')\n",
        "\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "\n",
        "with open('model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"TFLite model saved as model.tflite\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "z0mPLeYyzTfn",
        "outputId": "67984fe9-155d-40bf-dfc2-2f37750fc531"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmpggf1xb66'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name='input_layer')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 43), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  137912212806288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137912212802832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137912212815120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137912212802448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137912212814160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137912212811856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137912212804368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137912212815312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "TFLite model saved as model.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download('model.tflite')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "aaRAwZA50uGo",
        "outputId": "559a7bf7-bef0-42b1-e2fc-caf446dd9206"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_30b42657-f3cb-4094-9b57-7730a121c131\", \"model.tflite\", 1236992)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}